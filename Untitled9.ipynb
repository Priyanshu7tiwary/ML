{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshu7tiwary/ML/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pu-KsUp7KJYp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tuFTpIyyYSr7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, batch_files, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        for file in batch_files:\n",
        "            batch = unpickle(file)\n",
        "            images = batch[b'data'].reshape(-1, 3, 32, 32)  # Convert (10000, 3072) → (10000, 3, 32, 32)\n",
        "            labels = batch[b'labels']  # List of labels\n",
        "\n",
        "            self.data.append(images)\n",
        "            self.labels.extend(labels)\n",
        "\n",
        "        self.data = np.vstack(self.data)  # Combine all batches into a single array\n",
        "        self.data = torch.tensor(self.data, dtype=torch.uint8)  # Convert to tensor\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx], self.labels[idx]\n",
        "        image = image.float() / 255.0  # Normalize pixels (0-255 → 0-1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2I8DI7BCYiHF"
      },
      "outputs": [],
      "source": [
        "# List of batch files\n",
        "train_batch_files = [\n",
        "    \"/content/data_batch_1\",\n",
        "    \"/content/data_batch_2\",\"/content/data_batch_4\",\n",
        "    \"/content/data_batch_3\",\"/content/data_batch_5\"]\n",
        "\n",
        "\n",
        "test_batch_file = [\"/content/test_batch\"]\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "trainset = CIFAR10Dataset(train_batch_files, transform=transform)\n",
        "testset = CIFAR10Dataset(test_batch_file, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HWgyS_TLHC_"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoLCI8iNVY-x"
      },
      "source": [
        "define NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TcjDPqk2Vatm"
      },
      "outputs": [],
      "source": [
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "        self.conv1=nn.Conv2d(3,32,3,padding=1)\n",
        "        self.conv2=nn.Conv2d(32,64,3,padding=1)\n",
        "        self.pool=nn.MaxPool2d(2,2)\n",
        "        self.fc1=nn.Linear(64*8*8,128)\n",
        "        self.fc2=nn.Linear(128,10)\n",
        "        self.relu=nn.ReLU()\n",
        "        self.dropout=nn.Dropout(0.5)\n",
        "    def forward(self,x):\n",
        "        x=self.pool(self.relu(self.conv1(x)))\n",
        "        x=self.pool(self.relu(self.conv2(x)))\n",
        "        x=x.view(-1,64*8*8)\n",
        "        x=self.relu(self.fc1(x))\n",
        "        x=self.dropout(x)\n",
        "        x=self.fc2(x)\n",
        "        return x\n",
        "model = ImageClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftDLGnBpYwFf"
      },
      "source": [
        "loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "J3fCmYpaYv7o"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_phAayDRZiAy"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TQf-b9fYZi4u"
      },
      "outputs": [],
      "source": [
        "epochs=10\n",
        "for epoch in range(epochs):\n",
        "    running_loss=0.0\n",
        "    for i,data in enumerate(trainloader,0):\n",
        "        optimizer.zero_grad()\n",
        "        inputs,labels=data\n",
        "        outputs=model(inputs)\n",
        "        loss=criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cndVEMW9Z5aN"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c232Rv8wZ481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548cca8d-0a95-4ef9-b42c-e32070bd5020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60.56\n"
          ]
        }
      ],
      "source": [
        "correct=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images,labels=data\n",
        "        outputs=model(images)\n",
        "        _,predicted=torch.max(outputs.data,1)\n",
        "        total+=labels.size(0)\n",
        "        correct+=(predicted==labels).sum().item()\n",
        "print(100*correct/total)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTVyVr2dAO0IRnMybC2rPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}